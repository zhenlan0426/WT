{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cdb\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import timeit\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "store = cdb.use('mrg')\n",
    "with store.open(\"/e737253/train_2.csv\",'rb') as f:\n",
    "    train1  = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing = train1.isnull()\n",
    "train1 = train1.fillna(0)\n",
    "train1.iloc[:,1:] = train1.iloc[:,1:].astype(np.float32)\n",
    "n = train1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train1.Page.str.split('mediawiki.org|wikimedia.org|wikipedia.org',expand=True)\n",
    "b = np.where(a.loc[:,2].isnull(),a.loc[:,1],a.loc[:,2])\n",
    "_,index_array = np.unique(b,return_inverse=True) # access & agent\n",
    "website_array = [train1.Page.str.contains(web).values.astype(np.int8) \\\n",
    "                 for web in ['mediawiki.org','wikimedia.org','wikipedia.org']] # website\n",
    "lang_array = train1.Page.str.extract('([a-z]{2}).wikipedia').fillna('nan').values.flatten()\n",
    "_,lang_array = np.unique(lang_array,return_inverse=True) # language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Page_X = \\\n",
    "np.concatenate([OneHotEncoder(dtype=np.float32,sparse=False).fit_transform(lang_array[:,np.newaxis]),\\\n",
    "                OneHotEncoder(dtype=np.float32,sparse=False).fit_transform(index_array[:,np.newaxis]),\\\n",
    "                np.stack(website_array,1)],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_index=pd.to_datetime(train1.columns[1:]).to_series().reset_index(drop=True)\n",
    "def extract_date_info(timestamp,mss):\n",
    "    return np.array([mss, timestamp.weekday(), timestamp.month, timestamp.day, \\\n",
    "                     timestamp.dayofyear,timestamp.year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = extract_date_info(date_index[3],3).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_ = lambda df,start,interval: np.max(df.iloc[:,start-interval:start].values,1)\n",
    "min_ = lambda df,start,interval: np.min(df.iloc[:,start-interval:start].values,1)\n",
    "std_ = lambda df,start,interval: np.std(df.iloc[:,start-interval:start].values,1)\n",
    "mean_ = lambda df,start,interval: np.mean(df.iloc[:,start-interval:start].values,1)\n",
    "growth_ = lambda df,start,interval: np.mean(df.iloc[:,start-interval:start],1) -\\\n",
    "                                    np.mean(df.iloc[:,start-2*interval:start-interval],1)\n",
    "\n",
    "fun_list = [max_,min_,std_,mean_,growth_]\n",
    "interval_list = [14,30,60,120]\n",
    "T = train1.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#margain_ = np.median(train1.iloc[:,1:].values,1)\n",
    "#margain_ = np.where(margain_==0,-20,np.log(margain_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "downSampleRate = 0.5\n",
    "j = T - 64\n",
    "Lookback_X = np.stack([fun(train1,j,interval) for fun in fun_list for interval in interval_list],1)\n",
    "testData = []\n",
    "testMargain = []\n",
    "for i in range(j+2,j+64):\n",
    "    temp = np.concatenate([train1.iloc[:,i].values[:,np.newaxis],\\\n",
    "                           Page_X,\\\n",
    "                           np.broadcast_to(extract_date_info(date_index[i-1],i-j),(n,d)),\\\n",
    "                           Lookback_X,\\\n",
    "                           train1.iloc[:,j-1:j].values,\\\n",
    "                           train1.iloc[:,i-90:i-89].values,\\\n",
    "                           train1.iloc[:,i-120:i-119].values,\\\n",
    "                           train1.iloc[:,i-180:i-179].values,\\\n",
    "                           train1.iloc[:,i-365:i-364].values],1).astype(np.float32)\n",
    "    nonmissing_index = np.logical_not(missing.iloc[:,i].values)\n",
    "    random_index = np.random.rand(nonmissing_index.sum())<downSampleRate\n",
    "    testData.append(temp[nonmissing_index][random_index])\n",
    "    #testMargain.append(margain_[nonmissing_index][random_index])\n",
    "    testMargain.append(train1.iloc[:,j-1].values[nonmissing_index][random_index])\n",
    "testData = np.concatenate(testData,0)\n",
    "testMargain = np.concatenate(testMargain,0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downSampleRate = 0.1\n",
    "trainData = []\n",
    "trainMargain = []\n",
    "for j in range(T-65*2,350,-70):\n",
    "    Lookback_X = np.stack([fun(train1,j,interval) for fun in fun_list for interval in interval_list],1)\n",
    "    for i in range(j+2,j+64):\n",
    "        temp = np.concatenate([train1.iloc[:,i].values[:,np.newaxis],\\\n",
    "                               Page_X,\\\n",
    "                               np.broadcast_to(extract_date_info(date_index[i-1],i-j),(n,d)),\\\n",
    "                               Lookback_X,\\\n",
    "                               train1.iloc[:,j-1:j].values,\\\n",
    "                               train1.iloc[:,i-90:i-89].values,\\\n",
    "                               train1.iloc[:,i-120:i-119].values,\\\n",
    "                               train1.iloc[:,i-180:i-179].values,\\\n",
    "                               train1.iloc[:,i-365:i-364].values],1).astype(np.float32)\n",
    "        nonmissing_index = np.logical_not(missing.iloc[:,i].values)\n",
    "        random_index = np.random.rand(nonmissing_index.sum())<downSampleRate\n",
    "        trainData.append(temp[nonmissing_index][random_index])\n",
    "        #trainMargain.append(margain_[nonmissing_index][random_index])\n",
    "        trainMargain.append(train1.iloc[:,j-1].values[nonmissing_index][random_index])\n",
    "trainData = np.concatenate(trainData,0)\n",
    "trainMargain = np.concatenate(trainMargain,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data corruption when creating a a DMatrix with label being a non-contiguous ndarray #2554\n",
    "dtrain = xgb.DMatrix(np.ascontiguousarray(trainData[:,1:]),label=np.ascontiguousarray(trainData[:,0]))\n",
    "dtest = xgb.DMatrix(np.ascontiguousarray(testData[:,1:]),label=np.ascontiguousarray(testData[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain.set_base_margin(trainMargain)\n",
    "dtest.set_base_margin(testMargain)\n",
    "watchlist = [(dtest, 'eval'), (dtrain, 'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-parameter tuning with random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_gen = {'eps':[np.random.choice,[0.1,1,5,10,50]],\\\n",
    "            'neg_grad':[np.random.choice,[-0.1,-1,-5,-10,-50]],\\\n",
    "            'max_depth':[np.random.choice,[4,8,12,16,24,32]],\\\n",
    "            'subsample':[np.random.choice,[0.001,0.0025,0.005,0.01,0.025,0.05]],\\\n",
    "            'colsample_bylevel':[np.random.choice,[0.5,0.75,1]],\\\n",
    "            'gamma':[np.random.choice,[0.1,1,10,100,1000]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_(para_gen):\n",
    "    return {key:item[0](item[1]) for key,item in para_gen.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomSearch(fun,para_gen,dtrain,dtest,iterations):\n",
    "    # fun needs to have args Xtrain,ytrain,Xtest,ytest\n",
    "    for _ in range(iterations):\n",
    "        paras = generate_(para_gen)\n",
    "        paras_data = paras.copy()\n",
    "        paras_data['dtrain'] = dtrain\n",
    "        paras_data['dtest'] = dtest\n",
    "        paras['score'] = fun(**paras_data)\n",
    "        print(paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_xgb(dtrain,dtest,eps,neg_grad,max_depth,subsample,colsample_bylevel,gamma):\n",
    "    \n",
    "    def SMAPE_train(preds, dtrain):\n",
    "        y = dtrain.get_label()\n",
    "        temp = (2*y+eps)/(preds+y+eps)**2\n",
    "        grad = np.where(preds>y,temp,np.where(preds<0,neg_grad,-1*temp))\n",
    "        #index_ = np.isfinite(grad)\n",
    "        #non_index_ = np.logical_not(index_)\n",
    "        #print(preds[non_index_],y[non_index_])\n",
    "        hess = np.ones_like(grad)\n",
    "        return grad, hess\n",
    "    \n",
    "    num_round = 500\n",
    "    params =   {'eta': 1e-1,\n",
    "                'max_bin': 32,       \n",
    "                'nthread':8,       \n",
    "                'tree_method':'hist',                \n",
    "                'max_depth': max_depth, \n",
    "                'subsample': subsample,\n",
    "                'colsample_bylevel': colsample_bylevel, \n",
    "                'gamma': gamma\n",
    "                }\n",
    "    \n",
    "    model_gbm = xgb.train(params, dtrain, num_round, obj=SMAPE_train,verbose_eval=False)\n",
    "    return SMAPE_eval(model_gbm.predict(dtest), dtest)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomSearch(fun_xgb,para_gen,dtrain,dtest,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after hyper-parameter tuning, find the best num_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eps = 0.1\n",
    "floor = 0.1\n",
    "neg_grad = -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SMAPE_train(preds, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    temp = (2*y+eps)/(preds+y+eps)**2\n",
    "    grad = np.where(preds>y,temp,np.where(preds<0,neg_grad,-1*temp))\n",
    "    #index_ = np.isfinite(grad)\n",
    "    #non_index_ = np.logical_not(index_)\n",
    "    #print(preds[non_index_],y[non_index_])\n",
    "    hess = np.ones_like(grad)\n",
    "    return grad, hess\n",
    "\n",
    "def SMAPE_eval(preds, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    summ = np.abs(y) + np.abs(preds)\n",
    "    return 'SMAPE', 200*np.mean(np.where(summ==0, 0, np.abs(y - preds) / summ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_round = 5000\n",
    "params =   {'eta': 1e-1,\n",
    "            'max_depth': 8, \n",
    "            'max_bin': 32,\n",
    "            'subsample': 0.025,\n",
    "            'colsample_bylevel': 0.75, \n",
    "            'min_child_weight':100,\n",
    "            'tree_method':'hist',\n",
    "            'gamma': 0,\n",
    "            'nthread':8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "model_gbm = xgb.train(params, dtrain, num_round, watchlist, \\\n",
    "                      verbose_eval=100,\\\n",
    "                      obj=SMAPE_train, feval=SMAPE_eval)\n",
    "print(\"--- %s seconds ---\" % (timeit.default_timer() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit final model with both train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data corruption when creating a a DMatrix with label being a non-contiguous ndarray #2554\n",
    "dtrain = xgb.DMatrix(np.ascontiguousarray(np.concatenate([trainData[:,1:],testData[:,1:]],0)),\\\n",
    "                     np.ascontiguousarray(np.concatenate([trainData[:,0],testData[:,0]],0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain.set_base_margin(np.ascontiguousarray(np.concatenate([trainMargain,testMargain],0)))\n",
    "watchlist = [(dtrain, 'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_round = 5000\n",
    "params =   {'eta': 1e-1,\n",
    "            'max_depth': 8, \n",
    "            'max_bin': 32,\n",
    "            'subsample': 0.01,\n",
    "            'colsample_bylevel': 0.75, \n",
    "            'min_child_weight':100,\n",
    "            'tree_method':'hist',\n",
    "            'gamma': 0,\n",
    "            'nthread':8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "model_gbm = xgb.train(params, dtrain, num_round, watchlist, \\\n",
    "                      verbose_eval=500,\\\n",
    "                      obj=SMAPE_train, feval=SMAPE_eval)\n",
    "print(\"--- %s seconds ---\" % (timeit.default_timer() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_index.append(pd.Series(pd.date_range('2017-09-11','2017-11-13')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "j = T - 64 # TODO: change this\n",
    "Lookback_X = np.stack([fun(train1,j,interval) for fun in fun_list for interval in interval_list],1)\n",
    "testData = []\n",
    "testMargain = []\n",
    "mapping_index = []\n",
    "for i in range(j+2,j+64):\n",
    "    temp = np.concatenate([Page_X,\\\n",
    "                           np.broadcast_to(extract_date_info(date_index[i-1],i-j),(n,d)),\\\n",
    "                           Lookback_X,\\\n",
    "                           train1.iloc[:,j-1:j].values,\\\n",
    "                           train1.iloc[:,i-90:i-89].values,\\\n",
    "                           train1.iloc[:,i-120:i-119].values,\\\n",
    "                           train1.iloc[:,i-180:i-179].values,\\\n",
    "                           train1.iloc[:,i-365:i-364].values],1).astype(np.float32)\n",
    "\n",
    "    testData.append(temp)\n",
    "    testMargain.append(train1.iloc[:,j-1].values)\n",
    "    mapping_index.append(train1.iloc[:,0].str.cat([str(date_index[i-1])[:10]]*n,'_'))\n",
    "    \n",
    "testData = np.concatenate(testData,0)\n",
    "testMargain = np.concatenate(testMargain,0)\n",
    "mapping_index = np.concatenate(mapping_index,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data corruption when creating a a DMatrix with label being a non-contiguous ndarray #2554\n",
    "dtest = xgb.DMatrix(np.ascontiguousarray(testData))\n",
    "dtest.set_base_margin(np.ascontiguousarray(testMargain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yhat = model_gbm.predict(dtest,output_margin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'mapping_index':mapping_index,'':yhat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MRG [ml_py36.18.06.r2]",
   "language": "python",
   "name": "mrg_default[ml_py36.18.06.r2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
